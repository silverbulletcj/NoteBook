## 第三章 Apache Flink架构

*  系统架构
  * Flink在已有集群基础设施和服务之上专注于自身的核心功能，分布式流处理
  * 搭建Flink所需组件
    * JobManager：**主进程，控制着单个应用程序的执行**；JobManager接收需要执行的应用，其包含一个JobGraph，即逻辑Dataflow图，以及包含了所需类、库等资源的jar；JobManager会将JobGraph转化成ExecutionGraph，从ResourceManager处申请必要资源，满足后，将ExcutionGraph中的任务分发给TaskManager来执行；执行过程中，还负责所有需要集中协调的操作
    * ResourceManager：**负责管理Flink的处理资源单元-TaskManager处理槽**，在JobManager申请TaskManager处理槽时，会指示有空闲处理槽的TaskManager将其处理槽分配给JobManager，如果不够，会向资源提供者申请启动更多TaskManager进程，且负责终止空闲的TaskManager
    * TaskManager：**Flink的工作进程**；TaskManager在启动后，会在ResourceManager注册其处理槽；执行期间，运行同一应用不同任务的TaskManager之间会产生数据交换
    * Dispatcher：**提供REST接口让我们提交需要执行的应用**；一旦某个应用提交，就会启动一个JobManager并将应用转交给它
  * 应用部署
    * 框架模式：Flink应用会打包成一个JAR文件，通过客户端提交到运行的服务上
    * 库模式：Flink应用会绑定到一个特定应用的容器镜像
  * 任务执行
    * 一个TaskManager允许同时执行多个任务，这些任务可以属于同一个算子(数据并行)，也可以是不同的算子(任务并行)，甚至可以是来自不同的应用(作业并行)
    * 将任务以切片的形式调度至处理槽中的好处：多个任务可以在同一进程内高效的执行数据交换而无需访问网络
    * TaskManager会在同一个JVM进程内以多线程的方式执行任务
  * 高可用性设置
    * TaskManager故障
      * TaskManager发生故障，则意味着没有足够的处理槽用于任务执行，此时JobManager会向ResourceManager申请，如果无法完成申请，则JobManager无法重启应用，直到有足够数量的可用处理槽
    * JobManager故障
      * Flink中的高可用模式是基于ZooKeeper来完成的；在高可用模式下，JobManager会将JobGraph以及全部所需的元数据写入远程持久化存储系统中；此外，JobManager会将存储位置写入ZooKeeper的数据存储中
      * 在应用执行时，JobManager会接收每个任务检查点的(存储位置)，在任务检查点即将完成的时候，如果所有任务都将各自状态成功写入远程存储，那么JobManager就会将状态句柄写入远程存储，并将路径位置写入ZooKeeper
      * JobManager发生故障时，新的JobManager会执行以下步骤
        * 向ZooKeeper请求存储位置，以获取JobGraph、JAR文件及应用最新检查点在远程存储的状态句柄
        * 向ResourceManager申请处理槽继续执行应用
        * 重启应用且利用最近一次检查点重置任务状态
* Flink中的数据传输
  * TaskManager负责将数据从发送任务至接收任务，网络模块在传输前会将它们收集到缓冲区中
  * 基于信用值的流量控制
    * 工作原理：接收任务会给发送任务授予一定的信用值，用于保留一些用来接收它数据的缓冲；发送端在收到信用通知后，会尽可能的在信用值范围内传送缓冲数据，并附带上积压量；接收端通过保留的缓冲来处理数据，且根据各发送端的积压量信息计算所有连接的发送端在下一轮的优先级
  * 任务链接
    * 用于降低某些情况下的本地通信开销
    * 将多个算子的函数融合到一个任务中
* 事件时间处理
  * 时间戳：**在事件时间模式下，Flink流式应用处理的所有记录都必须包含时间戳**；需要保证流记录的时间戳会随着流数据的前进大致向前递增即可
  * 水位线(WaterMark)
    * **水位线用于在事件时间应用中推断每个任务当前的事件时间**
    * 水位线的两个基本属性：必须单调递增；和记录的时间戳存在联系，即一个时间戳为T的水位线表示接下来所有记录的时间戳一定都大于T
  * 水位线传播和事件时间
    * 任务内部的时间服务会维护一些计数器，依靠接收到水位线来激活
    * 当任务接收到一个水位线时执行的操作：
      * 基于水位线记录的时间戳更新内部事件时间时钟
      * 任务的时间服务会找出所有触发时间小于更新后事件时间的计时器
      * 任务根据更新后的事件时间将水位线发出
    * Flink的水位线处理和传播算法保证了算子任务所发出的记录时间戳和水位线一定会对齐；
    * 时间戳分配和水位线生成
      * 通常在数据流刚刚进入流处理应用的时候分配和生成的
        * 在数据源完成：利用SourceFunction在应用读入输入数据流的时候分配时间戳和水位线
        * 周期分配器：DataStream API提供AssignerWithPeriodicWatermarks的用户自定义函数，从每条记录读取时间戳，并周期性的响应获取当前水位线的查询请求
        * 定点分配器：根据特殊输入记录生成水位线的情况，用AssignerWithPunctuatedWatermarks的用户自定义函数
* 状态管理
  * 在Flink中，根据作用域的不同，状态可以分为两类：算子状态和键值分区状态
    * 算子状态：**作用域是某个算子任务**，意味着所有在同一个并行任务之内的记录都能访问到相同的状态
      * 列表状态：将状态表示为一个条目列表
      * 联合列表状态：将状态表示为一个条目列表，在进行故障恢复时有所不同
      * 广播状态：专门为需要保证算子的每个任务状态都相同的场景设计
    * 键值分区状态：会按照算子输入记录所定义的键值来进行维护或者是访问
      * 单值状态：每个键对应存储一个任意类型的值，该值也可以是复杂的数据结构
      * 列表状态：每个键对应存储一个值的列表，列表的条目可以是任意类型
      * 映射状态：每个键对应一个键值映射
  * 状态后端
    * 状态后端负责：本地状态管理和将状态以检查点的形式写入远程存储
    * 本地状态管理：存储所有键值分区状态，可以存在JVM堆中或者是RocksDB中
  * 有状态算子的扩缩容
    * 带有键值分区状态的算子：将所有键值分为不同的键值组，以此为单位分配给不同任务
    * 带有算子列表状态的算子：将所有的并行算子任务的列表头目统一收集起来，均匀的分配
    * 带有算子联合列表状态的算子：将状态列表的全部条目广播到全部任务上
    * 带有算子广播状态的算子：把状态全部拷贝到全部新任务上
* 检查点、保存点及状态恢复
  * Flink检查点算法
    * 基于**Chandy-Lamport分布式快照算法**实现，该算法会把生成检查点的过程和处理过程分离
    * 算法工作原理：用检查点分隔符(checkpoint barrier)，通过数据源算子注入到常规的记录流中，每个检查点分隔符都有一个检查点编号，这样就会将一条数据流从逻辑上分为了两部分
      * 数据源任务收到消息后，暂停发出记录，利用状态后端生成本地状态的检查点，将该检查点分隔符和编号广播至所有传出的数据流分区，状态后端在状态存为检查点后完成通知任务，之后任务会给JobManager发送确认消息
      * 将所有的分隔符发出后，数据源将恢复正常工作
      * 数据源任务发出的检查点分隔符会传输到与之相连的任务
      * 当任务收到一个新的检查点的分隔符时，会继续等待所有其他输入分区也发来这个检查点的分隔符；对于已经提供分隔符的分区，会将传输过来的数据进行缓冲，不处理；这个过程称为分隔符对齐；
      * 任务收集到了所有输入分区的检查点分隔符后，会通知状态后端开始生成检查点，同时将分隔符广播到下游相连的任务
      * 任务在发出所有的检查点分隔符后就开始处理缓冲的记录
      * 最终检查点分隔符到达数据汇任务，执行分隔符对齐，将自身状态写入检查点，向JobManager确认已经接收分隔符
      * JobManager在接收到所有应用任务返回的检查点确认消息后，就会将此次检查点标记为完成
  * 检查点对性能的影响
    * 任务在将其状态存入检查点的过程中，会处于阻塞状态；且在生成检查点的过程中，需要将这些数据通过网络写入远程存储系统中，而这一步可以通过在本地拷贝一份复制，后台进程将本地状态快照拷贝到远程存储，然后在完成检查点后通知任务
  * 保存点
    * 检查点会周期性的生成，且会根据配置的策略自动丢弃；而保存点可以看作包含一些额外元数据的检查点，需要用户显示触发
    * 保存点的使用
      * 从保存点启动一个不同但相互兼容的应用
      * 用不同的并行度启动原应用，从而实现应用的扩缩容
      * 在另一个集群上启动相同的应用
      * 利用保存点暂停某个应用，稍后再启动
      * 为保存点设置不同版本并将应用状态归档



